{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a041265-5d4f-4ae3-8c7a-dabb672b0db2",
   "metadata": {},
   "source": [
    "#### ESP32 Stereo Camera Code with navigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25f813a1-d342-4ce3-9bd3-760a5b8ab46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import math\n",
    "import time\n",
    "import requests\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import scipy.optimize\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms.functional as tvtf\n",
    "from torchvision.models.detection import MaskRCNN_ResNet50_FPN_Weights,MaskRCNN_ResNet50_FPN_V2_Weights\n",
    "\n",
    "#this is the file with auxillary functions. stereo_image_utils.py. Should be in the same\n",
    "#directory as the notebook\n",
    "import stereo_image_utils\n",
    "from stereo_image_utils import get_detections, get_cost, draw_detections, annotate_class2 \n",
    "from stereo_image_utils import get_horiz_dist_corner_tl, get_horiz_dist_corner_br, get_dist_to_centre_tl, get_dist_to_centre_br, get_dist_to_centre_cntr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a25d2a9e-dadd-4d8f-b2b2-d82deca85141",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_left = \"http://192.168.1.181\"\n",
    "URL_right = \"http://192.168.1.129\"\n",
    "URL_car = \"http://192.168.1.182\"\n",
    "AWB = True\n",
    "cnt = 0\n",
    "moved = False\n",
    "total_angle = 0\n",
    "brk = False\n",
    "#focal length. Pre-calibrated in stereo_image_v6 notebook\n",
    "fl = 2.043636363636363\n",
    "tantheta = 0.7648732789907391-0.1\n",
    "starttime = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69fb78e9-a034-4ee7-a494-4c05894819bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights=MaskRCNN_ResNet50_FPN_V2_Weights.DEFAULT\n",
    "\n",
    "COLOURS = [\n",
    "    tuple(int(colour_hex.strip('#')[i:i+2], 16) for i in (0, 2, 4))\n",
    "    for colour_hex in plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "946b04d2-f3d4-4c92-a399-dcca23652d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.detection.maskrcnn_resnet50_fpn_v2(weights=weights)\n",
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc60b19f-e830-44b0-85cf-96e9b836c8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#capture the images\n",
    "# cap_left = cv2.VideoCapture(URL_left + \":81/stream\")\n",
    "# cap_right = cv2.VideoCapture(URL_right + \":81/stream\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bbde1af-f138-40c2-bc12-38c0b940cbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions for the command handler\n",
    "\n",
    "def set_resolution(url: str, index: int=1, verbose: bool=False):\n",
    "    try:\n",
    "        if verbose:\n",
    "            resolutions = \"10: UXGA(1600x1200)\\n9: SXGA(1280x1024)\\n8: XGA(1024x768)\\n7: SVGA(800x600)\\n6: VGA(640x480)\\n5: CIF(400x296)\\n4: QVGA(320x240)\\n3: HQVGA(240x176)\\n0: QQVGA(160x120)\"\n",
    "            print(\"available resolutions\\n{}\".format(resolutions))\n",
    "\n",
    "        if index in [10, 9, 8, 7, 6, 5, 4, 3, 0]:\n",
    "            requests.get(url + \"/control?var=framesize&val={}\".format(index))\n",
    "        else:\n",
    "            print(\"Wrong index\")\n",
    "    except:\n",
    "        print(\"SET_RESOLUTION: something went wrong\")\n",
    "\n",
    "def set_quality(url: str, value: int=1, verbose: bool=False):\n",
    "    try:\n",
    "        if value >= 10 and value <=63:\n",
    "            requests.get(url + \"/control?var=quality&val={}\".format(value))\n",
    "    except:\n",
    "        print(\"SET_QUALITY: something went wrong\")\n",
    "\n",
    "def set_awb(url: str, awb: int=1):\n",
    "    try:\n",
    "        awb = not awb\n",
    "        requests.get(url + \"/control?var=awb&val={}\".format(1 if awb else 0))\n",
    "    except:\n",
    "        print(\"SET_QUALITY: something went wrong\")\n",
    "    return awb\n",
    "\n",
    "def set_angle(url: str, angle: int):\n",
    "    try:\n",
    "        requests.get(url + \"/action?angle={}\".format(angle))\n",
    "    except:\n",
    "        print(\"SET_ANGLE: something went wrong\")\n",
    "\n",
    "\n",
    "def set_distance(url: str, dist: int):\n",
    "    try:\n",
    "        requests.get(url + \"/action?distance={}\".format(dist))\n",
    "    except:\n",
    "        print(\"SET_ANGLE: something went wrong\")\n",
    "#26 37 38\n",
    "\n",
    "def set_speed(url: str, speed: int):\n",
    "    try:\n",
    "        requests.get(url + \"/slider?value={}\".format(speed))\n",
    "    except:\n",
    "        print(\"SET_SPEED: something went wrong\")\n",
    "\n",
    "def object_upright(coords):\n",
    "    return (abs(coords[0] - coords[2]) < abs(coords[1] - coords[3]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a439ab70-14e6-4e98-9e9c-029f93200eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_speed(URL_car, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a5b4050-7365-44b8-897e-9cb9692e062c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_angle(URL_car, int(-8.8998))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5720717-41ce-4164-b0b9-87f96fe9b891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bottle']\n",
      "['bottle']\n",
      "is bottle\n",
      "object upright\n",
      "1.4403852939605712\n",
      "bottle is 35.4cm away\n",
      "move angle 1\n",
      "['refrigerator']\n",
      "['refrigerator']\n",
      "refrigerator is 209.3cm away\n",
      "['cup' 'bottle']\n",
      "['cup']\n",
      "cup is 55.9cm away\n",
      "['cup' 'toilet' 'refrigerator']\n",
      "['cup']\n",
      "cup is 56.3cm away\n",
      "['cup' 'bowl' 'refrigerator']\n",
      "['cup' 'dining table']\n",
      "cup is 59.3cm away\n",
      "refrigerator is -4.8cm away\n",
      "['cup' 'car']\n",
      "['car' 'cup']\n",
      "cup is 54.3cm away\n",
      "car is 50.8cm away\n",
      "['cup' 'car' 'refrigerator' 'refrigerator']\n",
      "['cup' 'car']\n",
      "cup is 56.4cm away\n",
      "car is 51.8cm away\n",
      "['bottle' 'car' 'hair drier']\n",
      "['bottle' 'car']\n",
      "is bottle\n",
      "object upright\n",
      "2.756794166564941\n",
      "bottle is 44.7cm away\n",
      "car is 53.2cm away\n",
      "move angle 2\n",
      "['bottle']\n",
      "['bottle']\n",
      "is bottle\n",
      "object upright\n",
      "5.15407190322876\n",
      "bottle is 44.1cm away\n",
      "move angle 5\n",
      "['refrigerator']\n",
      "['backpack' 'refrigerator']\n",
      "refrigerator is 71.9cm away\n",
      "['suitcase']\n",
      "['suitcase']\n",
      "suitcase is 155.8cm away\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    set_resolution(URL_left, index=8)\n",
    "    set_resolution(URL_right, index=8)\n",
    "    set_speed(URL_car, 230)\n",
    "    \n",
    "    time.sleep(5)\n",
    "    \n",
    "\n",
    "    while True:\n",
    "        mov_angle = []\n",
    "        mov_dists = []\n",
    "#         print('here')\n",
    "        ### capture the images\n",
    "#         cap_left.release()\n",
    "#         cap_right.release()\n",
    "\n",
    "        cap_left = cv2.VideoCapture(URL_left + \":81/stream\")\n",
    "\n",
    "        cap_right = cv2.VideoCapture(URL_right + \":81/stream\")\n",
    "        if cap_left.isOpened():\n",
    "            ret_l, frame_l = cap_left.read()\n",
    "            #release the capture to stop a queu building up. I'm sure there are more efficient ways to do this.\n",
    "            cap_left.release()\n",
    "            \n",
    "            if ret_l:\n",
    "                cv2.imshow(\"left_eye\", frame_l) \n",
    "#             else:\n",
    "#                 cap_left.release()\n",
    "#                 cap_left = cv2.VideoCapture(URL_left + \":81/stream\")\n",
    "                \n",
    "        if cap_right.isOpened():\n",
    "            ret_r, frame_r = cap_right.read()\n",
    "            cap_right.release()\n",
    "\n",
    "            if ret_r:\n",
    "                cv2.imshow(\"right_eye\", frame_r) \n",
    "#             else:\n",
    "#                 cap_right.release()\n",
    "#                 cap_right = cv2.VideoCapture(URL_right + \":81/stream\")\n",
    "        \n",
    "        if ret_r and ret_l :\n",
    "            #do stereo matching\n",
    "            imgs = [cv2.cvtColor(frame_l, cv2.COLOR_BGR2RGB),cv2.cvtColor(frame_r, cv2.COLOR_BGR2RGB)]\n",
    "            if cnt == 0:\n",
    "#                 cnt = 0\n",
    "                \n",
    "                #do the inference\n",
    "                det, lbls, scores, masks = get_detections(model,imgs,score_threshold=0.5)\n",
    "                if(len(det[0])==0 or len(det[1])==0):\n",
    "                    set_angle(URL_car, 7) ##move five degrees and check environment again.\n",
    "                    total_angle += 7\n",
    "                    continue\n",
    "\n",
    "                sz1 = frame_r.shape[1]\n",
    "                centre = sz1/2\n",
    "        \n",
    "                #print out inference results\n",
    "#                 print(det)\n",
    "                print(np.array(weights.meta[\"categories\"])[lbls[0]])\n",
    "                print(np.array(weights.meta[\"categories\"])[lbls[1]])\n",
    "                cost = get_cost(det, lbls = lbls,sz1 = centre)\n",
    "                \n",
    "                #do the tracking from left eye to right eye.\n",
    "                tracks = scipy.optimize.linear_sum_assignment(cost)\n",
    "\n",
    "                dists_tl =  get_horiz_dist_corner_tl(det)\n",
    "                dists_br =  get_horiz_dist_corner_br(det)\n",
    "\n",
    "                final_dists = []\n",
    "                dctl = get_dist_to_centre_tl(det[0],cntr = centre)\n",
    "                dcbr = get_dist_to_centre_br(det[0], cntr = centre)\n",
    "                \n",
    "                #measure distance of object from the centre so I can see how far I need to turn.\n",
    "                d0centre = get_dist_to_centre_cntr(det[0], cntr = centre)\n",
    "                d1centre = get_dist_to_centre_cntr(det[1], cntr = centre)\n",
    "                \n",
    "                #find the angle I need \n",
    "                for i, j in zip(*tracks):\n",
    "                    if (np.array(weights.meta[\"categories\"])[lbls[0]][i])=='bottle':\n",
    "                        print('is bottle')\n",
    "                        #check if bottle is till upright\n",
    "                        if object_upright(det[0][i]):\n",
    "                            print('object upright')\n",
    "#                             break\n",
    "                            angle = (d0centre[i]+d1centre[j])/sz1*9 #15 worked well in experiments can play around with this.\n",
    "                            # if objects are all the way to the right, then turn 15*2 30 degrees right\n",
    "                            mov_angle.append(int(angle))\n",
    "                            print(angle)\n",
    "                        else:\n",
    "                            print('object flat')\n",
    "#                             break\n",
    "                    if (lbls[0][i]==lbls[1][j] or True):\n",
    "                        if dctl[i] < dcbr[i]:\n",
    "                            final_dists.append((dists_tl[i][j],np.array(weights.meta[\"categories\"])[lbls[0]][i]))\n",
    "\n",
    "                        else:\n",
    "                            final_dists.append((dists_br[i][j],np.array(weights.meta[\"categories\"])[lbls[0]][i]))\n",
    "                    \n",
    "                    else: #put zero if they are different objects.\n",
    "                        final_dists.append((0,np.array(weights.meta[\"categories\"])[lbls[0]][i]))\n",
    "                \n",
    "                #final distances as list\n",
    "                \n",
    "                fd = [i for (i,j) in final_dists]\n",
    "                #find distance away\n",
    "                dists_away = (7.05/2)*sz1*(1/tantheta)/np.array((fd))+fl\n",
    "                cat_dist = []\n",
    "                for i in range(len(dists_away)):\n",
    "                    if (np.array(weights.meta[\"categories\"])[lbls[0]][(tracks[0][i])])=='bottle':\n",
    "                        mov_dists.append(dists_away[i])\n",
    "                    cat_dist.append(f'{np.array(weights.meta[\"categories\"])[lbls[0]][(tracks[0][i])]} {dists_away[i]:.1f}cm')\n",
    "                    print(f'{np.array(weights.meta[\"categories\"])[lbls[0]][(tracks[0][i])]} is {dists_away[i]:.1f}cm away')\n",
    "                t1 = [list(tracks[1]), list(tracks[0])]\n",
    "                frames_ret = []\n",
    "                for i, imgi in enumerate(imgs):\n",
    "                    img = imgi.copy()\n",
    "                    deti = det[i].astype(np.int32)\n",
    "                    draw_detections(img,deti[list(tracks[i])], obj_order=list(t1[1]))\n",
    "                    annotate_class2(img,deti[list(tracks[i])],lbls[i][list(tracks[i])],cat_dist)\n",
    "                    frames_ret.append(img)\n",
    "                cv2.imshow(\"left_eye\", cv2.cvtColor(frames_ret[0],cv2.COLOR_RGB2BGR))\n",
    "                cv2.imshow(\"right_eye\", cv2.cvtColor(frames_ret[1],cv2.COLOR_RGB2BGR))\n",
    "                \n",
    "                if (mov_dists and mov_dists[0] > 100): #don't move more than 100cm at this stage of testing.\n",
    "                    continue\n",
    "                \n",
    "                if(not moved and mov_angle):\n",
    "                    set_angle(URL_car, mov_angle[0])\n",
    "                    print('move angle', mov_angle[0])\n",
    "                    time.sleep(2)\n",
    "                    if mov_angle[0] > 0:\n",
    "                        total_angle += mov_angle[0]\n",
    "\n",
    "                    if(mov_dists):                       \n",
    "                        set_distance(URL_car, mov_dists[0]+3)\n",
    "#                         cap_right = cv2.VideoCapture(URL_right + \":81/stream\")\n",
    "                        starttime = time.time()\n",
    "#                         while ((time.time() - starttime) < 2.5):\n",
    "#                             ret_r, frame_r = cap_right.read()\n",
    "#                             if ret_r:\n",
    "#                                 cv2.imshow(\"right_eye\", frame_r) \n",
    "#                         cap_left.release()\n",
    "                        time.sleep(3) ##wait two seconds, then reverse.\n",
    "                        set_distance(URL_car, -mov_dists[0]-3)\n",
    "                        starttime = time.time()\n",
    "#                         while ((time.time() - starttime) < 2.5):\n",
    "#                             ret_r, frame_r = cap_right.read()\n",
    "#                             if ret_r:\n",
    "#                                 cv2.imshow(\"right_eye\", frame_r) \n",
    "#                         cap_right.release()\n",
    "                        time.sleep(3)\n",
    "                \n",
    "                if (total_angle < 720): #two rounds\n",
    "                    set_angle(URL_car, 7) ##move five degrees and check environment again.\n",
    "                    total_angle += 7\n",
    "                    time.sleep(2)\n",
    "                else: \n",
    "                    brk = True\n",
    "                    break\n",
    "                \n",
    "#                 while True and False:\n",
    "#                     key1 = cv2.waitKey(1)\n",
    "#                     if key1 == ord('p'):\n",
    "#                         break\n",
    "#                 key1 = cv2.waitKey(1)\n",
    "        \n",
    "        key = cv2.waitKey(1)\n",
    "        if brk:\n",
    "            break\n",
    "\n",
    "        if key == ord('r'):\n",
    "            idx = int(input(\"Select resolution index: \"))\n",
    "            set_resolution(URL_left, index=idx, verbose=True)\n",
    "            set_resolution(URL_right, index=idx, verbose=True)\n",
    "\n",
    "        elif key == ord('q'):\n",
    "            val = int(input(\"Set quality (10 - 63): \"))\n",
    "            set_quality(URL_left, value=val)\n",
    "            set_quality(URL_right, value=val)\n",
    "\n",
    "        elif key == ord('a'):\n",
    "            AWB = set_awb(URL_left, AWB)\n",
    "            AWB = set_awb(URL_right, AWB)\n",
    "            \n",
    "        elif key == ord('p'): #3d\n",
    "            cnt = 0\n",
    "\n",
    "        elif key == 27:\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    cap_left.release()\n",
    "    cap_right.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc49a1cb-2d92-4f66-8d9d-399b649a9faa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
