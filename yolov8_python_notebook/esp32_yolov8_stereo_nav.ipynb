{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a50cd710-6a98-49d4-bf63-5407df0b0982",
   "metadata": {},
   "source": [
    "### Stereo Camera YOLOV8 with navigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08dca647-4736-481a-b1d6-6d4916ae4f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.19  Python-3.9.6 torch-1.12.1+cpu CPU\n",
      "Setup complete  (8 CPUs, 15.8 GB RAM, 431.0/475.7 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import math\n",
    "import ultralytics\n",
    "ultralytics.checks()\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import pandas\n",
    "import time\n",
    "import requests\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import scipy.optimize\n",
    "import torch\n",
    "\n",
    "import stereo_image_utils\n",
    "from stereo_image_utils import get_detections, get_cost, draw_detections, annotate_class2 \n",
    "from stereo_image_utils import get_horiz_dist_corner_tl, get_horiz_dist_corner_br, get_dist_to_centre_tl, get_dist_to_centre_br, get_dist_to_centre_cntr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4186abc0-52ac-4cc7-848c-d8279ec1ebcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions for the command handler\n",
    "\n",
    "def set_resolution(url: str, index: int=1, verbose: bool=False):\n",
    "    try:\n",
    "        if verbose:\n",
    "            resolutions = \"10: UXGA(1600x1200)\\n9: SXGA(1280x1024)\\n8: XGA(1024x768)\\n7: SVGA(800x600)\\n6: VGA(640x480)\\n5: CIF(400x296)\\n4: QVGA(320x240)\\n3: HQVGA(240x176)\\n0: QQVGA(160x120)\"\n",
    "            print(\"available resolutions\\n{}\".format(resolutions))\n",
    "\n",
    "        if index in [10, 9, 8, 7, 6, 5, 4, 3, 0]:\n",
    "            requests.get(url + \"/control?var=framesize&val={}\".format(index))\n",
    "        else:\n",
    "            print(\"Wrong index\")\n",
    "    except:\n",
    "        print(\"SET_RESOLUTION: something went wrong\")\n",
    "\n",
    "def set_quality(url: str, value: int=1, verbose: bool=False):\n",
    "    try:\n",
    "        if value >= 10 and value <=63:\n",
    "            requests.get(url + \"/control?var=quality&val={}\".format(value))\n",
    "    except:\n",
    "        print(\"SET_QUALITY: something went wrong\")\n",
    "\n",
    "def set_awb(url: str, awb: int=1):\n",
    "    try:\n",
    "        awb = not awb\n",
    "        requests.get(url + \"/control?var=awb&val={}\".format(1 if awb else 0))\n",
    "    except:\n",
    "        print(\"SET_QUALITY: something went wrong\")\n",
    "    return awb\n",
    "\n",
    "def set_angle(url: str, angle: int):\n",
    "    try:\n",
    "        requests.get(url + \"/action?angle={}\".format(angle))\n",
    "    except:\n",
    "        print(\"SET_ANGLE: something went wrong\")\n",
    "\n",
    "\n",
    "#This is the equivalent funciton to set_angle in javascript        \n",
    "# function toggleCheckbox(angle) {\n",
    "#     var xhr = new XMLHttpRequest();\n",
    "#     xhr.open(\"GET\", \"/action?angle=\" + angle, true);\n",
    "#     xhr.send();\n",
    "# }\n",
    "\n",
    "def set_distance(url: str, dist: int):\n",
    "    try:\n",
    "        requests.get(url + \"/action?distance={}\".format(dist))\n",
    "    except:\n",
    "        print(\"SET_DISTANCE: something went wrong\")\n",
    "\n",
    "\n",
    "def set_speed(url: str, speed: int):\n",
    "    try:\n",
    "        requests.get(url + \"/slider?value={}\".format(speed))\n",
    "    except:\n",
    "        print(\"SET_SPEED: something went wrong\")\n",
    "\n",
    "#26 37 38\n",
    "\n",
    "def object_upright(coords):\n",
    "    return (abs(coords[0] - coords[2]) < abs(coords[1] - coords[3]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cca6607-78e4-4906-8672-e600a9f58a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#n, s, m, l, x\n",
    "# see https://github.com/ultralytics/ultralytics for more information\n",
    "model = YOLO(\"yolov8m.pt\")\n",
    "#class names\n",
    "names =  model.model.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ebc7d7a-c5e6-41f2-9c75-17a5b84580ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#camera url. I've used a static url in the esp32 cam sketc.\n",
    "# connecting through local network with url = 192.168.1.xxx\n",
    "# might need to change this if you are connecting through an iphone hotspot or some other network\n",
    "URL_left = \"http://192.168.1.181\"\n",
    "URL_right = \"http://192.168.1.129\"\n",
    "URL_car = \"http://192.168.1.182\"\n",
    "AWB = True\n",
    "cnt = 0\n",
    "moved = False\n",
    "total_angle = 0\n",
    "brk = False\n",
    "#focal length. Pre-calibrated in stereo_image_v6 notebook\n",
    "fl = 2.043636363636363\n",
    "tantheta = 0.7648732789907391-0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5630b3f3-37d9-4228-a008-513fbf10d8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#capture the images\n",
    "# cap_left = cv2.VideoCapture(URL_left + \":81/stream\")\n",
    "# cap_right = cv2.VideoCapture(URL_right + \":81/stream\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3589c1-d797-46a0-a631-04ad9318d180",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.19  Python-3.9.6 torch-1.12.1+cpu CPU\n",
      "YOLOv8x summary (fused): 268 layers, 68200608 parameters, 0 gradients, 257.8 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[        569,         184,         764,         635]], dtype=float32), array([[        478,         144,         675,         594]], dtype=float32)]\n",
      "is bottle\n",
      "object upright\n",
      "3.2080078125\n",
      "bottle is 61.7cm away\n",
      "[array([[        680,         434,         820,         631]], dtype=float32), array([[        427,         390,         555,         595]], dtype=float32)]\n",
      "vase is 23.5cm away\n",
      "[array([[        785,         565,         975,         639],\n",
      "       [        381,         447,         516,         641]], dtype=float32), array([[        689,         527,         875,         603]], dtype=float32)]\n",
      "car is 58.6cm away\n",
      "[array([[        484,         564,         657,         635],\n",
      "       [         63,         456,         216,         669],\n",
      "       [        993,         393,        1024,         648]], dtype=float32), array([[        390,         523,         564,         594]], dtype=float32)]\n",
      "car is 59.8cm away\n",
      "[array([[        677,          81,         906,         640],\n",
      "       [        195,         573,         382,         655]], dtype=float32), array([[        579,          98,         802,         605],\n",
      "       [         89,         532,         285,         610]], dtype=float32)]\n",
      "is bottle\n",
      "object upright\n",
      "6.708984375\n",
      "bottle is 57.4cm away\n",
      "car is 58.0cm away\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    set_resolution(URL_left, index=10)\n",
    "    set_resolution(URL_right, index=10)\n",
    "    set_speed(URL_car, 230)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    while True:\n",
    "        mov_angle = []\n",
    "        mov_dists = []\n",
    "        ### capture the images\n",
    "\n",
    "        cap_left = cv2.VideoCapture(URL_left + \":81/stream\")\n",
    "\n",
    "        cap_right = cv2.VideoCapture(URL_right + \":81/stream\")\n",
    "        \n",
    "        if cap_left.isOpened():\n",
    "            ret_l, frame_l = cap_left.read()\n",
    "            #release the capture to stop a queu building up. I'm sure there are more efficient ways to do this.\n",
    "            cap_left.release()\n",
    "            \n",
    "            if ret_l:\n",
    "                cv2.imshow(\"left_eye\", frame_l) \n",
    "#             else:\n",
    "#                 cap_left.release()\n",
    "#                 cap_left = cv2.VideoCapture(URL_left + \":81/stream\")\n",
    "\n",
    "        if cap_right.isOpened():\n",
    "            ret_r, frame_r = cap_right.read()\n",
    "            #release the capture to stop a queu building up. I'm sure there are more efficient ways to do this.\n",
    "            cap_right.release()\n",
    "\n",
    "            if ret_r:\n",
    "                cv2.imshow(\"right_eye\", frame_r) \n",
    "#             else:\n",
    "#                 cap_right.release()\n",
    "#                 cap_right = cv2.VideoCapture(URL_right + \":81/stream\")\n",
    "        \n",
    "        if ret_r and ret_l :\n",
    "            imgs = [cv2.cvtColor(frame_l, cv2.COLOR_BGR2RGB),cv2.cvtColor(frame_r, cv2.COLOR_BGR2RGB)]\n",
    "            out_l = []\n",
    "            out_r =[]\n",
    "            #do stereo matching\n",
    "            if cnt == 0:  #this condition added mostly for debugging\n",
    "                out_l = (model.predict(source =cv2.cvtColor(frame_l, cv2.COLOR_BGR2RGB), save=False, conf = 0.4, save_txt=False, show = False ))[0]\n",
    "                out_r = (model.predict(source =cv2.cvtColor(frame_r, cv2.COLOR_BGR2RGB), save=False, conf = 0.4, save_txt=False, show = False ))[0]\n",
    "                \n",
    "            #do stereo pair matching. See file below for details.\n",
    "            # https://github.com/jonathanrandall/esp32_stereo_camera/blob/main/python_notebooks/stereo_image_v6.ipynb\n",
    "            \n",
    "            if (out_l.boxes.shape[0]<1 or out_r.boxes.shape[0]<1): #if I haven't detected anything move car and do another check\n",
    "                set_angle(URL_car, 10) ##move five degrees and check environment again.\n",
    "                total_angle += 10\n",
    "                continue\n",
    "            \n",
    "            if cnt == 0 and (out_l.boxes.shape[0]>0 and out_r.boxes.shape[0]>0): #cnt is just a control for debugging\n",
    "                #boxes are the coordinates of the boudning boxes.\n",
    "                cnt = 0 #1\n",
    "                \n",
    "                #find the image centre\n",
    "                sz1 = frame_r.shape[1]\n",
    "                centre = sz1/2\n",
    "\n",
    "                #dets are bounding boxes and lbls are labels.\n",
    "                det = []\n",
    "                lbls = []\n",
    "                \n",
    "                #det[0] are the bounding boxes for the left image\n",
    "                #det[1] are the bounding boxes for the right image\n",
    "\n",
    "                if(out_l.boxes.shape[0]>0 and out_r.boxes.shape[0]>0):\n",
    "                    det.append(np.array(out_l.boxes.xyxy))\n",
    "                    det.append(np.array(out_r.boxes.xyxy))\n",
    "                    lbls.append(out_l.boxes.cls)\n",
    "                    lbls.append(out_r.boxes.cls)\n",
    "                \n",
    "                print(det)\n",
    "                \n",
    "                #get the cost of matching each object in the left image\n",
    "                #to each object in the right image\n",
    "                cost = get_cost(det, lbls = lbls,sz1 = centre)\n",
    "                \n",
    "                #choose optimal matches based on the cost.\n",
    "                tracks = scipy.optimize.linear_sum_assignment(cost)                \n",
    "                \n",
    "                #find top left and bottom right corner distance to centre (horizonatlly)\n",
    "                dists_tl =  get_horiz_dist_corner_tl(det)\n",
    "                dists_br =  get_horiz_dist_corner_br(det)\n",
    "\n",
    "                final_dists = []\n",
    "                dctl = get_dist_to_centre_tl(det[0],cntr = centre)\n",
    "                dcbr = get_dist_to_centre_br(det[0], cntr = centre)\n",
    "                \n",
    "                #measure distance of object from the centre so I can see how far I need to turn.\n",
    "                d0centre = get_dist_to_centre_cntr(det[0], cntr = centre)\n",
    "                d1centre = get_dist_to_centre_cntr(det[1], cntr = centre)\n",
    "                \n",
    "                #classes for left and right images. nm0 is left, nm1 is right\n",
    "                q = [i.item() for i in lbls[0]]\n",
    "                nm0 = [names[i] for i in q]\n",
    "                q = [i.item() for i in lbls[1]]\n",
    "                nm1 = [names[i] for i in q]\n",
    "                \n",
    "                #check if bottle is upright. height greater than width and move car certain angle.\n",
    "\n",
    "                for i, j in zip(*tracks):\n",
    "                    if (nm0[i])=='bottle':\n",
    "                        print('is bottle')\n",
    "                        #check if bottle is till upright\n",
    "                        if object_upright(det[0][i]):\n",
    "                            print('object upright')\n",
    "#                             break\n",
    "                            angle = (d0centre[i]+d1centre[j])/sz1*15 #15 worked well in experiments can play around with this.\n",
    "                            # if objects are all the way to the right, then turn 15*2 30 degrees right\n",
    "                            mov_angle.append(int(angle))\n",
    "                            print(angle)\n",
    "                        else:\n",
    "                            print('object flat')\n",
    "#                             break\n",
    "                    if dctl[i] < dcbr[i]:\n",
    "                        final_dists.append((dists_tl[i][j],nm0[i]))\n",
    "\n",
    "                    else:\n",
    "                        final_dists.append((dists_br[i][j],nm0[i]))\n",
    "                \n",
    "                #final distances as list\n",
    "                fd = [i for (i,j) in final_dists]\n",
    "                #find distance away\n",
    "                dists_away = (7.05/2)*sz1*(1/tantheta)/np.array((fd))+fl\n",
    "                cat_dist = []\n",
    "                for i in range(len(dists_away)):\n",
    "                    if (nm0[i])=='bottle':\n",
    "                        mov_dists.append(dists_away[i])\n",
    "                    cat_dist.append(f'{nm0[(tracks[0][i])]} {dists_away[i]:.1f}cm')\n",
    "                    print(f'{nm0[(tracks[0][i])]} is {dists_away[i]:.1f}cm away')\n",
    "                t1 = [list(tracks[1]), list(tracks[0])]\n",
    "                frames_ret = []\n",
    "                for i, imgi in enumerate(imgs):\n",
    "                    img = imgi.copy()\n",
    "                    deti = det[i].astype(np.int32)\n",
    "                    draw_detections(img,deti[list(tracks[i])], obj_order=list(t1[1]))\n",
    "                    annotate_class2(img,deti[list(tracks[i])],lbls[i][list(tracks[i])],cat_dist)\n",
    "                    frames_ret.append(img)\n",
    "                cv2.imshow(\"left_eye\", cv2.cvtColor(frames_ret[0],cv2.COLOR_RGB2BGR))\n",
    "                cv2.imshow(\"right_eye\", cv2.cvtColor(frames_ret[1],cv2.COLOR_RGB2BGR))\n",
    "                \n",
    "                if (mov_dists and mov_dists[0] > 100): #don't move more than 100cm at this stage of testing.\n",
    "                    continue\n",
    "                \n",
    "                if(not moved and mov_angle):\n",
    "                    set_angle(URL_car, mov_angle[0])\n",
    "                    time.sleep(2)\n",
    "                    if mov_angle[0] > 0:\n",
    "                        total_angle += mov_angle[0]\n",
    "#                     moved = True\n",
    "                    if(mov_dists):                       \n",
    "                        set_distance(URL_car, mov_dists[0]+3)\n",
    "                        time.sleep(2) ##wait two seconds, then reverse.\n",
    "                        set_distance(URL_car, -mov_dists[0]-3)\n",
    "                        time.sleep(2)\n",
    "                \n",
    "                if (total_angle < 720): #two rounds\n",
    "                    set_angle(URL_car, 10) ##move five degrees and check environment again.\n",
    "                    total_angle += 10\n",
    "                    time.sleep(2)\n",
    "                else: \n",
    "                    brk = True\n",
    "                    break\n",
    "#                 while True:\n",
    "#                     key1 = cv2.waitKey(1)\n",
    "#                     if key1 == ord('p'):\n",
    "#                         break\n",
    "#                 key1 = cv2.waitKey(1)\n",
    "\n",
    "            key = cv2.waitKey(1)\n",
    "\n",
    "            if key == ord('r'):\n",
    "                idx = int(input(\"Select resolution index: \"))\n",
    "                set_resolution(URL, index=idx, verbose=True)\n",
    "\n",
    "            elif key == ord('q'):\n",
    "                val = int(input(\"Set quality (10 - 63): \"))\n",
    "                set_quality(URL, value=val)\n",
    "\n",
    "            elif key == ord('a'):\n",
    "                AWB = set_awb(URL, AWB)\n",
    "                \n",
    "            elif key == ord('p'):\n",
    "                cnt = 0\n",
    "\n",
    "            elif key == 27: #esc key\n",
    "                print(out_l)\n",
    "                break\n",
    "    cv2.destroyAllWindows()\n",
    "    cap_left.release()\n",
    "    cap_right.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe937924-eaad-4fe9-a112-f256f4216973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Properties:\n",
    "#     234             xyxy (torch.Tensor) or (numpy.ndarray): The boxes in xyxy format.\n",
    "#     235             conf (torch.Tensor) or (numpy.ndarray): The confidence values of the boxes.\n",
    "#     236             cls (torch.Tensor) or (numpy.ndarray): The class values of the boxes.\n",
    "#     237             xywh (torch.Tensor) or (numpy.ndarray): The boxes in xywh format.\n",
    "#     238             xyxyn (torch.Tensor) or (numpy.ndarray): The boxes in xyxy format normalized by original image size.\n",
    "#     239             xywhn (torch.Tensor) or (numpy.ndarray): The boxes in xywh format normalized by original image size.\n",
    "#     240         \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c26826-f267-4c78-8ccf-111429b7cbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "q=[int(i.item()) for i in lbls[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35022e0-0d1a-4948-8f30-8988a306e1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46ba4a9-8bdb-4dda-991f-a705d09f87ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "int(-10.716796875)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5d2af0-cd47-4de4-a27d-7d8a366b8dbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
